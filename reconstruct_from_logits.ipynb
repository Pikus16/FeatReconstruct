{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/content_understanding/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, models, datasets\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "from utils import get_model, get_transforms, get_dataset, get_features, get_recon_loss, learn_reconstruct, do_feat_recon, get_logits_from_feats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the predicted logits from a ResNet18, pretrained on ImageNet, can we learn the features with a single linear layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model('resnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 50000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transform = get_transforms('cifar100')\n",
    "train_set, test_set = get_dataset('cifar100', test_transform=test_transform, get_train=True)\n",
    "len(test_set), len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:29, 52.88it/s]                          \n",
      "313it [00:06, 49.26it/s]                         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((50000, 512), (10000, 512), (50000, 1000), (10000, 1000))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_feats_train, cifar_logits_train, cifar_labels_train = get_features(model, train_set)\n",
    "cifar_feats_test, cifar_logits_test, cifar_labels_test = get_features(model, test_set)\n",
    "cifar_feats_train.shape, cifar_feats_test.shape, cifar_logits_train.shape, cifar_logits_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss=82.71377904620022, test loss = 5.457098842598498\n",
      "Epoch 10, train loss=7.264157226425596, test loss = 1.5426271691685542\n",
      "Epoch 20, train loss=4.583923751953989, test loss = 0.9979622986866161\n",
      "Epoch 30, train loss=3.319168064976111, test loss = 0.7295367528568022\n",
      "Epoch 40, train loss=2.5593346460082103, test loss = 0.5646934271790087\n",
      "Epoch 50, train loss=2.0483272130950354, test loss = 0.4522753198398277\n",
      "Epoch 60, train loss=1.6807755785412155, test loss = 0.37070933749782853\n",
      "Epoch 70, train loss=1.4042739442666061, test loss = 0.30904794664820656\n",
      "Epoch 80, train loss=1.189472611164092, test loss = 0.26104325967025943\n",
      "Epoch 90, train loss=1.0185217096150154, test loss = 0.22283535328460857\n"
     ]
    }
   ],
   "source": [
    "recon_model = learn_reconstruct(cifar_logits_train, cifar_feats_train, cifar_logits_test, cifar_feats_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_cifar_feats_test = do_feat_recon(cifar_logits_test, recon_model)\n",
    "recon_cifar_feats_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [00:00, 382.99it/s]                         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_recon = get_logits_from_feats(recon_cifar_feats_test,  model.original_fc)\n",
    "preds_recon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9935"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_recon = np.argmax(preds_recon, axis=1)\n",
    "top_orig = np.argmax(cifar_logits_test, axis=1)\n",
    "np.mean(top_orig == top_recon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on CIFAR-100 train, and testing on CIFAR-100 test, we get a reconstruction, MSE loss of 0.224 total over the 10k test examples.\n",
    "\n",
    "If we take these reconstructed features and then use the model's linear head, the top-1 prediction matches the original prediction 99.24% of the time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the predicted logits from a ResNet18, pretrained on ImageNet, can we learn the features from a pretrained ResNet50 with a single linear layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = get_model('resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:59, 26.34it/s]                          \n",
      "313it [00:12, 25.56it/s]                         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((50000, 2048), (10000, 2048), (50000, 1000), (10000, 1000))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cifar_feats_train_resnet50, cifar_logits_train_resnet50, cifar_labels_train_resnet50 = get_features(resnet50, train_set)\n",
    "cifar_feats_test_resnet50, cifar_logits_test_resnet50, cifar_labels_test_resnet50 = get_features(resnet50, test_set)\n",
    "cifar_feats_train_resnet50.shape, cifar_feats_test_resnet50.shape, cifar_logits_train_resnet50.shape, cifar_logits_test_resnet50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss=39.300385073293, test loss = 2.8255152758210897\n",
      "Epoch 10, train loss=3.7770108753466047, test loss = 0.7561160636250861\n",
      "Epoch 20, train loss=3.034100213786587, test loss = 0.6142645400250331\n",
      "Epoch 30, train loss=2.717832017049659, test loss = 0.5525207920582034\n",
      "Epoch 40, train loss=2.5255862835620064, test loss = 0.5147924707562197\n",
      "Epoch 50, train loss=2.3897917853319086, test loss = 0.48809869555407204\n",
      "Epoch 60, train loss=2.285780160455033, test loss = 0.4676349123183172\n",
      "Epoch 70, train loss=2.201998257514788, test loss = 0.4511379585310351\n",
      "Epoch 80, train loss=2.132155106140999, test loss = 0.4373734011896886\n",
      "Epoch 90, train loss=2.072465785226086, test loss = 0.4255984641495161\n"
     ]
    }
   ],
   "source": [
    "recon_model_resnet50 = learn_reconstruct(cifar_logits_train_resnet50, cifar_feats_train_resnet50, cifar_logits_test_resnet50, cifar_feats_test_resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [00:00, 393.13it/s]                         \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9822"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_cifar_feats_test_resnet50 = do_feat_recon(cifar_logits_test_resnet50, recon_model_resnet50)\n",
    "preds_recon_resnet50 = get_logits_from_feats(recon_cifar_feats_test_resnet50,  resnet50.original_fc)\n",
    "top_recon = np.argmax(preds_recon_resnet50, axis=1)\n",
    "top_orig = np.argmax(cifar_logits_test_resnet50, axis=1)\n",
    "np.mean(top_orig == top_recon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on CIFAR-100 train, and testing on CIFAR-100 test, we get a reconstruction, MSE loss of 5.17 total over the 10k test examples.\n",
    "\n",
    "If we take these reconstructed features and then use the model's linear head, the top-1 prediction matches the original prediction 99.47% of the time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the predicted logits from a ResNet18, pretrained on ImageNet, can we learn the features with a single linear layer, while training / testing on a different dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places_test = get_dataset(\"places365\", get_train=False)\n",
    "len(places_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1141it [00:23, 49.08it/s]                          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((36500, 512), (36500, 1000))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places_feats_test, places_logits_test, places_labels_test = get_features(model, places_test)\n",
    "places_feats_test.shape, places_logits_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1141it [00:01, 629.53it/s]                          \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9765205479452055"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_places_feats_test = do_feat_recon(places_logits_test, recon_model)\n",
    "places_preds_recon = get_logits_from_feats(recon_places_feats_test,  model.original_fc)\n",
    "top_recon = np.argmax(places_preds_recon, axis=1)\n",
    "top_orig = np.argmax(places_logits_test, axis=1)\n",
    "np.mean(top_orig == top_recon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take these reconstructed features and then use the model's linear head, the top-1 prediction matches the original prediction 96.48% of the time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the predicted logits from a ResNet18, pretrained on ImageNet, can we learn the features from a ViT model with a single linear layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "clip_vit, _, test_transform = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 50000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = datasets.CIFAR10(root=f'/home/ubuntu/data/cifar10', train=False, download=True, transform=test_transform)\n",
    "train_set = datasets.CIFAR10(root=f'/home/ubuntu/data/cifar10', train=True, download=True, transform=test_transform)\n",
    "len(test_set), len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CLIP' object has no attribute 'fc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ubuntu/code/FeatReconstruct/reconstruct_from_logits.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbenp_main/home/ubuntu/code/FeatReconstruct/reconstruct_from_logits.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m cifar_feats_train_vit \u001b[39m=\u001b[39m get_features(clip_vit, train_set)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbenp_main/home/ubuntu/code/FeatReconstruct/reconstruct_from_logits.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m cifar_feats_test_vit \u001b[39m=\u001b[39m get_features(clip_vit, test_set)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbenp_main/home/ubuntu/code/FeatReconstruct/reconstruct_from_logits.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m cifar_feats_train_vit\u001b[39m.\u001b[39mshape, cifar_feats_test_vit\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;32m/home/ubuntu/code/FeatReconstruct/reconstruct_from_logits.ipynb Cell 39\u001b[0m in \u001b[0;36mget_features\u001b[0;34m(model, dataset, batch_size, num_workers)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbenp_main/home/ubuntu/code/FeatReconstruct/reconstruct_from_logits.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_features\u001b[39m(model, dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, num_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbenp_main/home/ubuntu/code/FeatReconstruct/reconstruct_from_logits.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     original_fc \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(model\u001b[39m.\u001b[39;49mfc)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbenp_main/home/ubuntu/code/FeatReconstruct/reconstruct_from_logits.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     model\u001b[39m.\u001b[39mfc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mIdentity()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbenp_main/home/ubuntu/code/FeatReconstruct/reconstruct_from_logits.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     model\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/content_understanding/lib/python3.8/site-packages/torch/nn/modules/module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1184\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1185\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1186\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CLIP' object has no attribute 'fc'"
     ]
    }
   ],
   "source": [
    "cifar_feats_train_vit = get_features(clip_vit, train_set)\n",
    "cifar_feats_test_vit = get_features(clip_vit, test_set)\n",
    "cifar_feats_train_vit.shape, cifar_feats_test_vit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "content_understanding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d36b139402f0f8909133622e5e80cdd43397350f551386f6df555aa508ab69d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
